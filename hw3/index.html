<html>
	<head>
		<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=default'></script>
		<link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600&display=swap" rel="stylesheet">
		<style>
			h1 {
				text-align: center;
			}

			.container {
				margin: 0 auto;
				padding: 60px 20%;
			}

			figure {
				text-align: center;
			}

			img {
				display: inline-block;
			}

			body {
				font-family: 'Inter', sans-serif;
			}
		</style>
	</head>
	<body>
		<div class="container">
		<h1>CS184/284A Spring 2025 Homework 3 Write-Up</h1>
		<div style="text-align: center;">Name: Ryan Arlett </div>

		<br>
		Link to webpage: <a href="https://cal-cs184-student.github.io/hw-webpages-ryan_a/">https://cal-cs184-student.github.io/hw-webpages-ryan_a/</a>
		<br>
		Link to GitHub repository: <a href="https://github.com/cal-cs184-student/sp25-hw3-ryana_hw3">https://github.com/cal-cs184-student/sp25-hw3-ryana_hw3</a>
		
		<figure>
			<img src="cornell.png" alt="Cornell Boxes with Bunnies" style="width:70%"/>
			<figcaption>You can add images with captions!</figcaption>
		</figure>

		<!--
		We've already added one heading per part, to make your write-up as navigable when grading. Please fit your write-up within these sections!
		-->

		<h2>Overview</h2>
		Give a high-level overview of what you implemented in this homework. Think about what you've built as a whole. Share your thoughts on what interesting things you've learned from completing the homework.

		<h2>Part 1: Ray Generation and Scene Intersection</h2>
		<p>The first step in ray tracing is to first generate the rays that come out of the camera. For each pixel, I generate a fixed number of rays (given by the -s parameter). For each ray, I first sample a random x,y position inside that pixel using a uniform random sampler, then scale these coordinates down to normalized image coordinates (0 to 1), and pass them to my camera->generate_ray function.</p>
		<p>This function converts the given coordinates into a direction for the new ray, then converts this direction from the camera’s local space to world coordinates using the camera’s transformation matrix. This is the direction for the new ray, and the rays origin is simply set at the camera’s world space position. I also set the ray’s min_t and max_t to the camera’s clipping distances. Now, we want to know what each of these rays is going to hit, which requires ray intersection functions for each primitive in the scene (triangles and spheres).</p>
		<p>For ray-triangle intersections, I used the Moller-Trumbore algorithm given in discussion, which allows me to efficiently calculate the intersection time as well as the barycentric coordinates of the hit location. After this, I check that the intersection time is valid (within the ray’s min_t and max_t), and also that the barycentric coordinates are valid so we know that the hit location is actually inside the triangle. If these are both true, I fill in the intersection struct to contain the needed information about the hit, like the time, surface normal, and the primitive it hit. For the normal vector, I use the barycentric coordinates to interpolate the triangle’s vertex normals, making sure to normalize the result as it could no longer be normalized after interpolation. I also reduce the ray’s max_t to the time of the intersection so that it can no longer intersect with primitives behind this one.</p>
		<p>My ray-sphere intersection function uses a quadratic equation to solve for the times of intersection. After first checking if this equation has any solutions (using the quadratic equation), I again check that the times are within the ray’s valid window. If so, I fill in the intersection struct and update the ray’s max_t similarly to before. With this done, my renderer can now draw simple scenes with normal shading. The images below are rendered at 360p with 1 sample per pixel.</p>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="p1/p1_spheres.png" width="480px"/>
				</td>
				<td style="text-align: center;">
				  <img src="p1/p1_cow.png" width="480px"/>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="p1/p1_teapot.png" width="480px"/>
				</td>
				<td style="text-align: center;">
				  <img src="p1/p1_banana.png" width="480px"/>
				</td>
			  </tr>
			</table>
		</div>
		
		<h2>Part 2: Bounding Volume Hierarchy</h2>
		<p>Though the scenes above are fairly simple - only having a few thousand triangles at most - they were still quite slow to render, as each ray had to perform an intersection test on every primitive in the scene in linear O(N) time. A much more efficient way to render is to organize primitives into bounding boxes such that a ray only needs to perform intersection tests with the primitives in the boxes that it intersects. By organizing these bounding boxes into a binary search tree, we can reduce the time complexity of the intersection testing to O(log(N)), a massive improvement when we have many triangles.</p>
		<p>My implementation generates the tree by recursively splitting groups of primitives in half until it reaches a small enough number of primitives per box. I always split along the longest axis of the total bounding box of the primitives to hopefully get the greatest reduction in box surface area. As for the splitting point, I originally went with the average of the primitive’s centroids along the splitting axis. I then sorted the primitives by swapping only the ones that needed to be swapped in a QuickSort like algorithm. While this implementation worked, I found this would sometimes result in heavily one sided trees, especially in the Cornell Box scenes, where the large outside box would stay intertwined with the model in the middle to quite some depth. Thus, I decided to split at the median instead to guarantee an evenly sided tree. To be able to find the median I first have to completely sort the primitives, for which I just used std::sort() to make my life easier. I then split in the middle of this now sorted list of primitives, recursively calling the function on both halves of the list.</p>
		<p>With the BVH working I could now render much more complicated scenes in a fraction of the time, and could significantly increase the number of rays per pixel to get smoother results. Some complicated models rendered at 360p with 64 samples per pixel are shown below.</p>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="p2/p2_beast.png" width="480px"/>
				</td>
				<td style="text-align: center;">
				  <img src="p2/p2_dragon.png" width="480px"/>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="p2/p2_lucy.png" width="480px"/>
				</td>
				<td style="text-align: center;">
				  <img src="p2/p2_wall-e.png" width="480px"/>
				</td>
			  </tr>
			</table>
		</div>
		<p>For a quantitative look at the performance increase, when rendering the cow model (shown in part 1) at 480x360p with 1 sample per pixel, my renderer took 25.17s with no BVH acceleration and only 0.08s with the BVH. This huge performance increase is helped by the fact that the cow model can be divided quite well into bounding boxes due to its regular geometry. However, for simpler models like the Cornell Box spheres model (also shown in part 1), the BVH acceleration only improved the time from 4.43s to 3.54s when rendering both at 360p with 64 samples per pixel. This shows that for very simple geometry, as well as for models that cannot be divided up nicely like the large triangles of the Cornell Box, the BVH’s performance boost is less significant.</p>
		<h2>Part 3: Direct Illumination</h2>
		<p>Now that my renderer can quickly calculate ray intersections, I need a way to calculate the direct lighting at those intersection points. The mathematical answer to this question is the integral of all the incoming radiance over the hemisphere at that point, multiplied by the material’s bidirectional scattering distribution function (BSDF) to convert incoming radiance to outgoing radiance in the direction of the camera. However, since I cannot possibly solve this integral, I must estimate its answer with a Monte-Carlo estimator.</p>
		<p>The naive way to perform this estimate is to sample the incoming radiance uniformly over the hemisphere. My implementation does this by generating a randomly sampled direction for the new ray in the hemisphere, then converting it from local coordinates to world coordinates, then shooting the new ray in this direction. If this ray intersects the scene, I then get the incoming radiance from that direction using the emission property of the material it intersects. I then multiply by cos(θ) from Lambert's cosine law and divide by the probability of sampling a ray in that direction (which is just 1/2π since the sampling is uniform). Finally, I multiply by the BSDF to get the outgoing radiance to the camera. After taking the average of many of these estimated outgoing radiances, my Monte-Carlo estimate is complete and I am able to render direct lighting, as shown below. The L parameter gives how many of the new direct lighting sampling rays I use, and the S parameter is samples per pixel as before.</p>
		<figure>
			<img src="p3/p3_bunny_H_S16_L8.png" width="640px"/>
		  	<figcaption>Hemisphere Sampling: S=16 L=8</figcaption>
		</figure>
		<figure>
			<img src="p3/p3_bunny_H_S64_L32.png" width="640px"/>
		  	<figcaption>Hemisphere Sampling: S=64 L=32</figcaption>
		</figure>
		<figure>
			<img src="p3/p3_spheres_H_S64_L32.png" width="640px"/>
		  	<figcaption>Hemisphere Sampling: S=64 L=32</figcaption>
		</figure>
		<p>As you can see, there is significant noise in these images, especially at lower L. This is because the chance of any light sampling ray hitting the area light is low, so only a few of the rays actually contribute anything to the outgoing radiance. This gives a lot of noise as there is a decent chance of not having any light rays hit the area light at all. From this, we can see that it makes much more sense to send all our lighting rays in the direction of lights instead of wasting them uniformly over the hemisphere where most of them will end up hitting an object with no emission. This gives the idea of light importance sampling, which I implement as follows:</p>
		<p>For every area light in the scene, I generate a L random rays pointing towards it, and also record the incoming radiance from the light in that direction and the probability of sampling a ray in that direction. Then, I perform an intersection test to ensure that no object lies in between the hit point and the light. After this, I can use the same formula as before to perform a Monte-Carlo estimate of the outgoing radiance reflected from that area light. For point lights, my logic is the same, however I only take one sample for them as there is no reason to take L samples as they would all lie in the same direction. After summing up the contributions from every light, my importance sampling implementation is complete. As you can see below, this drastically reduces the noise in the renders, and also allows me to render scenes with point lights.</p>
		<figure>
			<img src="p3/p3_bunny_I_S16_L8.png" width="640px"/>
		  	<figcaption>Importance Sampling: S=16 L=8</figcaption>
		</figure>
		<figure>
			<img src="p3/p3_bunny_I_S64_L32.png" width="640px"/>
		  	<figcaption>Importance Sampling: S=64 L=32</figcaption>
		</figure>
		<figure>
			<img src="p3/p3_spheres_I_S64_L32.png" width="640px"/>
		  	<figcaption>Importance Sampling: S=64 L=32</figcaption>
		</figure>
		<figure>
			<img src="p3/p3_dragon_I_S64_L32.png" width="640px"/>
		  	<figcaption>Importance Sampling: S=64 L=32</figcaption>
		</figure>
		<figure>
			<img src="p3/p3_wall-e_I_S64_L32.png" width="640px"/>
		  	<figcaption>Importance Sampling: S=64 L=32</figcaption>
		</figure>
		<p>With importance sampling, at points where the entire area light is unobscured we would expect little noise even with a low L, as all the light rays will hit the light and get return similar radiances. However, at points such as soft shadows where the light is partially obscured, we get noise as some of the light rays are blocked while others aren’t. This requires L to be decently large to average this out and remove noise in soft shadows. As you can see in the images below, going up to L=64 is required to reduce noise in the soft shadow regions.</p>
		<figure>
			<img src="p3/p3_spheres_I_S1_L1.png" width="640px"/>
		  	<figcaption>Importance Sampling: S=1 L=1</figcaption>
		</figure>
		<figure>
			<img src="p3/p3_spheres_I_S1_L4.png" width="640px"/>
		  	<figcaption>Importance Sampling: S=1 L=4</figcaption>
		</figure>
		<figure>
			<img src="p3/p3_spheres_I_S1_L16.png" width="640px"/>
		  	<figcaption>Importance Sampling: S=1 L=16</figcaption>
		</figure>
		<figure>
			<img src="p3/p3_spheres_I_S1_L64.png" width="640px"/>
		  	<figcaption>Importance Sampling: S=1 L=64</figcaption>
		</figure>
		<p>Comparing these two implementations, importance sampling beats uniform sampling in every way. Since both are estimating the same integral, they have the same expected results at large L, but importance sampling is able to converge much quicker by only sampling from the rays that are going to contribute to the outgoing radiance (the ones going towards lights). This means importance sampling can produce the same images with a far lower L, which also makes it run much faster. Apart from the difference in noise, the only difference between the sets of images is that uniform sampling produces a glow around the light at the top of the Cornel Box while importance sampling doesn’t. This is just due to a slight difference in implementation where my uniform sampling implementation allows light to come out of the top side of the light, while importance sampling doesn’t.</p>
		<h2>Part 4: Global Illumination</h2>
		<p>While direct lighting looked mostly realistic, it ignores the possibility of light bouncing more than once between our camera and the light sources. One effect of this is that it makes the shadows in scenes darker than they should be, as the light that would have otherwise bounced around the object to get to that area is ignored. To get a fully realistic result, global illumination considers multiple bounce paths, which I implement as follows:</p>
		<p>First, I set each initial rays depth to zero before it leaves the camera. Then, at each intersection, I sample one new ray using the materials sampler (cosine weighted for diffuse materials) and assign a depth one greater to this ray. I then cast this ray into the world and recursively call this same function on its intersection. This recursion continues until we are one depth below the maximum requested depth (-m parameter), at which point I just return the direct illumination at that point using the function from part 3. The previous bounces then use their BDSF, cosine, and probability distribution terms to convert the radiance returned by the ray one deeper than them to the radiance they reflect back. If the accumulate bounces setting is on, I also add the direct lighting at that point to the returned radiance. Thus, every sample ends up taking M bounces, summing up how much direct lighting is reflected back along that path to the camera.</p>
		<p>This provides very realistic results, however we would have to set M to infinity to account for all possible light paths. Since this would run forever, we can instead use “Russian Roulette Termination” to terminate most of the rays at lower depths and only let a few continue to the deep depths. To do this, I modified my function to only continue the recursion with probability 0.65 (so 0.35 chance of termination), and if it does continue I increase its returned value by a factor of (1 / 0.65) to keep the result unbiased. This allows rendering to a very high M without it taking forever. However, it does increase variance in the image by adding this extra random factor which will slow down the convergence.</p>
		<p>Here are my results for global illumination. The three images below are rendered at S=1024, L=1, M=5, without russian roulette.</p>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="p4/p4_spheres_S1024_L1_M5.png" width="480px"/>
				</td>
				<td style="text-align: center;">
				  <img src="p4/p4_dragon_S1024_L1_M5.png" width="480px"/>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="p4/p4_wall-e_S1024_L1_M5.png" width="480px"/>
				</td>
				<td style="text-align: center;">
				  <img src="p4/p4_blob_S1024_L1_M5.png" width="480px"/>
				</td>
			  </tr>
			</table>
		</div>
		<p>To see the difference between direct and indirect illumination, the images below show each of them separately. The sum of these images would be the full global illumination image shown above. The indirect lighting was rendered to a max depth of 5 with no russian roulette. As you can see, indirect lighting allows light to reach areas that were completely dark in direct lighting.</p>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="p4/p4_spheres_S1024_L4_M1_DIRECT.png" width="480px"/>
		  		  <figcaption>Direct Only: S=1024 L=4</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="p4/p4_spheres_S1024_L4_M5_INDIRECT.png" width="480px"/>
				  <figcaption>Indirect Only: S=1024 L=4 M=5</figcaption>
				</td>
			  </tr>
			</table>
		</div>
			
		<p>The images below show the contributions of each bounce of light. The left images show just that depth of light (accumulate bounces disabled), while the right images have accumulate bounces enabled. As you can see, the 2nd and 3rd bounces help to fill in the shadows on the bottom of the bunny and the corners of the box. They also provide a noticeable reflection of the red and blue walls onto the sides of the bunny, which is a realistic effect that we missed with just direct lighting. All images below were rendered with S=1024, L=1, and russian roulette disabled so that all rays reached their requested depth.</p>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="p4/p4_bunny_S1024_L1_M0_O0.png" width="480px"/>
		  		  <figcaption>Accumulate Off, M=0</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="p4/p4_bunny_S1024_L1_M0_O1.png" width="480px"/>
		  		  <figcaption>Accumulate On, M=0</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="p4/p4_bunny_S1024_L1_M1_O0.png" width="480px"/>
		  		  <figcaption>Accumulate Off, M=1</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="p4/p4_bunny_S1024_L1_M1_O1.png" width="480px"/>
		  		  <figcaption>Accumulate On, M=1</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="p4/p4_bunny_S1024_L1_M2_O0.png" width="480px"/>
		  		  <figcaption>Accumulate Off, M=2</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="p4/p4_bunny_S1024_L1_M2_O1.png" width="480px"/>
		  		  <figcaption>Accumulate On, M=2</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="p4/p4_bunny_S1024_L1_M3_O0.png" width="480px"/>
		  		  <figcaption>Accumulate Off, M=3</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="p4/p4_bunny_S1024_L1_M3_O1.png" width="480px"/>
		  		  <figcaption>Accumulate On, M=3</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="p4/p4_bunny_S1024_L1_M4_O0.png" width="480px"/>
		  		  <figcaption>Accumulate Off, M=4</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="p4/p4_bunny_S1024_L1_M4_O1.png" width="480px"/>
		  		  <figcaption>Accumulate On, M=4</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="p4/p4_bunny_S1024_L1_M5_O0.png" width="480px"/>
		  		  <figcaption>Accumulate Off, M=5</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="p4/p4_bunny_S1024_L1_M5_O1.png" width="480px"/>
		  		  <figcaption>Accumulate On, M=5</figcaption>
				</td>
			  </tr>
			</table>
		</div>

		<p>Here is the same bunny at different depths again, but with russian roulette enabled.</p>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="p4/p4_bunny_S1024_L1_M0_RR.png" width="480px"/>
		  		  <figcaption>Russian Roulette On, M=0</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="p4/p4_bunny_S1024_L1_M1_RR.png" width="480px"/>
		  		  <figcaption>Russian Roulette On, M=1</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="p4/p4_bunny_S1024_L1_M2_RR.png" width="480px"/>
		  		  <figcaption>Russian Roulette On, M=2</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="p4/p4_bunny_S1024_L1_M3_RR.png" width="480px"/>
		  		  <figcaption>Russian Roulette On, M=3</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="p4/p4_bunny_S1024_L1_M4_RR.png" width="480px"/>
		  		  <figcaption>Russian Roulette On, M=4</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="p4/p4_bunny_S1024_L1_M100_RR.png" width="480px"/>
		  		  <figcaption>Russian Roulette On, M=100</figcaption>
				</td>
			  </tr>
			</table>
		</div>

		<p>The images below show how varying the pixel sampling rate (S) affects the image quality. They are rendered with L=4, M=100, and russian roulette enabled.</p>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="p4/p4_spheres_S1_L4_M100_RR.png" width="480px"/>
		  		  <figcaption>S=1</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="p4/p4_spheres_S2_L4_M100_RR.png" width="480px"/>
		  		  <figcaption>S=2</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="p4/p4_spheres_S4_L4_M100_RR.png" width="480px"/>
		  		  <figcaption>S=4</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="p4/p4_spheres_S8_L4_M100_RR.png" width="480px"/>
		  		  <figcaption>S=8</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="p4/p4_spheres_S16_L4_M100_RR.png" width="480px"/>
		  		  <figcaption>S=16</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="p4/p4_spheres_S64_L4_M100_RR.png" width="480px"/>
		  		  <figcaption>S=64</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="p4/p4_spheres_S256_L4_M100_RR.png" width="480px"/>
		  		  <figcaption>S=256</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="p4/p4_spheres_S1024_L4_M100_RR.png" width="480px"/>
		  		  <figcaption>S=1024</figcaption>
				</td>
			  </tr>
			</table>
		</div>
		<h2>Part 5: Adaptive Sampling</h2>
		<p>From the images above, you can see that some areas of an image can converge with fewer samples per pixel than others. This motivates the idea of adaptive sampling, where we stop sampling pixels early if we decide they have already converged. My algorithm uses two new parameters: the number of samples per batch, and a tolerance for deciding if a pixel has converged. For each pixel, I sample a batch of rays, summing up their illumination and illumination squared. With these metrics, I am able to calculate the mean and variance of all the samples so far, from which I use the provided equations that perform a z-test, getting a confidence interval in whether or not our mean is within the tolerance of the true mean. If it is within the tolerance, I end the sampling for that pixel early, otherwise I sample another batch, continuing either until it converges or until we hit the maximum number of samples given by the S parameter.</p>
		<p>The renderer also outputs images showing how many samples were taken per pixel, with red being the most and blue being the least. From this, we can see what areas of images converge faster. Also, I mentioned earlier that russian roulette increases variance, and we can now verify that as seen below. All images rendered at S=2048 L=1 M=5.</p>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="p5/p5_bunny_S2048_L1_M5.png" width="480px"/>
		  		  <figcaption>Bunny: Russian Roulette Disabled</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="p5/p5_bunny_S2048_L1_M5_rate.png" width="480px"/>
		  		  <figcaption>/<== Pixel Sampling Rate</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="p5/p5_bunny_S2048_L1_M5_RR.png" width="480px"/>
		  		  <figcaption>Bunny: Russian Roulette Enabled</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="p5/p5_bunny_S2048_L1_M5_RR_rate.png" width="480px"/>
		  		  <figcaption>/<== Pixel Sampling Rate</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="p5/p5_dragon_S2048_L1_M5.png" width="480px"/>
		  		  <figcaption>Dragon: Russian Roulette Disabled</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="p5/p5_dragon_S2048_L1_M5_rate.png" width="480px"/>
		  		  <figcaption>/<== Pixel Sampling Rate</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="p5/p5_wall-e_S2048_L1_M5.png" width="480px"/>
		  		  <figcaption>Dragon: Russian Roulette Disabled</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="p5/p5_wall-e_S2048_L1_M5_rate.png" width="480px"/>
		  		  <figcaption>/<== Pixel Sampling Rate</figcaption>
				</td>
			  </tr>
			</table>
		</div>
		
		</div>
	</body>
</html>
